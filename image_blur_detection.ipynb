{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MasoudMoeini/Image-blur-detection/blob/main/image_blur_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-5xmsZ5RQes",
        "outputId": "dd2d6605-fb32-4ef4-a1b4-2298bbfc0f9c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ],
      "source": [
        "%load_ext tensorboard\n",
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n",
        "import numpy as np\n",
        "import matplotlib . pyplot as plt\n",
        "from tensorflow.keras import layers, losses\n",
        "# Base CNN\n",
        "x = tf.placeholder(tf.float32, (None,224, 224, 3))\n",
        "y = tf.placeholder(tf.float32, (None,224, 224, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wJfwkZX9TC3O"
      },
      "outputs": [],
      "source": [
        "#!unzip -qq BlurDatasetResultShi.zip\n",
        "#!unzip -qq ccv_data.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8pmv42pPJ4SW"
      },
      "outputs": [],
      "source": [
        "rm -rf ./logs/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7BbR2mvcKA5S",
        "outputId": "b426728d-22e8-4192-a82b-9d9f9af03ad3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  after removing the cwd from sys.path.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/convolutional.py:575: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "  if __name__ == '__main__':\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:14: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/pooling.py:600: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:19: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:24: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:29: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:34: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:39: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:45: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:50: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:54: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:60: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:64: UserWarning: `tf.layers.conv2d` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: UserWarning: `tf.layers.max_pooling2d` is deprecated and will be removed in a future version. Please use `tf.keras.layers.MaxPooling2D` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:77: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/keras/legacy_tf_layers/convolutional.py:1736: UserWarning: `layer.apply` is deprecated and will be removed in a future version. Please use `layer.__call__` method instead.\n",
            "  return layer.apply(inputs)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:81: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:85: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:89: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:93: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:97: UserWarning: `tf.layers.conv2d_transpose` is deprecated and will be removed in a future version. Please Use `tf.keras.layers.Conv2DTranspose` instead.\n"
          ]
        }
      ],
      "source": [
        "# Conv1\n",
        "# Input Tensor Shape: [batch_size, 224, 224, 3]\n",
        "# Output Tensor Shape: [batch_size, 224, 228, 32]\n",
        "conv1 = tf.layers.conv2d(x, filters=32, kernel_size=[3,3], padding=\"same\", activation=tf.nn.relu)\n",
        "\n",
        "# conv2\n",
        "# Input Tensor Shape: [batch_size, 224, 224, 32]\n",
        "# Output Tensor Shape: [batch_size, 224, 228, 32]\n",
        "conv2 = tf.layers.conv2d(conv1, filters=32, kernel_size=[3,3], padding=\"same\", activation=tf.nn.relu)\n",
        "\n",
        "# pool1\n",
        "# Input Tensor Shape: [batch_size, 224, 224, 32]\n",
        "# Output Tensor Shape: [batch_size, 112, 112, 32]\n",
        "pool1 = tf.layers.max_pooling2d(conv2, pool_size=[2,2], strides=2, padding=\"same\")\n",
        "\n",
        "#conv3\n",
        "# Input Tensor Shape: [batch_size, 112, 112, 32]\n",
        "# Output Tensor Shape: [batch_size, 112, 112, 64]\n",
        "conv3 = tf.layers.conv2d(conv2, filters=64, kernel_size=[3,3], padding=\"same\", activation=tf.nn.relu)\n",
        "\n",
        "#conv4\n",
        "# Input Tensor Shape: [batch_size, 112, 112, 64]\n",
        "# Output Tensor Shape: [batch_size, 112, 112, 64]\n",
        "conv4 = tf.layers.conv2d(conv3, filters=64, kernel_size=[3,3], padding=\"same\", activation=tf.nn.relu)\n",
        "\n",
        "#pool2\n",
        "# Input Tensor Shape: [batch_size, 112, 112, 64]\n",
        "# Output Tensor Shape: [batch_size, 56, 56, 64]\n",
        "pool2 = tf.layers.max_pooling2d(conv4, pool_size=[2,2], strides=2, padding=\"same\")\n",
        "\n",
        "#conv5\n",
        "# Input Tensor Shape: [batch_size, 56, 56, 64]\n",
        "# Output Tensor Shape: [batch_size, 56, 56, 128]\n",
        "conv5 = tf.layers.conv2d(pool2, filters=128, kernel_size=[3,3], padding=\"same\", activation=tf.nn.relu)\n",
        "\n",
        "#conv6\n",
        "# Input Tensor Shape: [batch_size, 56, 56, 128]\n",
        "# Output Tensor Shape: [batch_size, 56, 56, 128]\n",
        "conv6 = tf.layers.conv2d(conv5, filters=128, kernel_size=[3,3], padding=\"same\", activation=tf.nn.relu)\n",
        "\n",
        "\n",
        "#pool3\n",
        "# Input Tensor Shape: [batch_size, 56, 56, 128]\n",
        "# Output Tensor Shape: [batch_size, 28, 28, 128]\n",
        "pool3 = tf.layers.max_pooling2d(conv6, pool_size=[2,2], strides=2, padding=\"same\")\n",
        "\n",
        "#conv7\n",
        "# Input Tensor Shape: [batch_size, 28, 28, 128]\n",
        "# Output Tensor Shape: [batch_size, 28, 28, 256]\n",
        "conv7 = tf.layers.conv2d(pool3, filters=256, kernel_size=[3,3], padding=\"same\", activation=tf.nn.relu)\n",
        "#conv8\n",
        "# Input Tensor Shape: [batch_size, 28, 28, 256]\n",
        "# Output Tensor Shape: [batch_size, 28, 28, 256]\n",
        "conv8 = tf.layers.conv2d(conv7, filters=128, kernel_size=[3,3], padding=\"same\", activation=tf.nn.relu)\n",
        "\n",
        "#pool4\n",
        "# Input Tensor Shape: [batch_size, 28, 28, 256]\n",
        "# Output Tensor Shape: [batch_size, 14, 14, 256]\n",
        "\n",
        "pool4 = tf.layers.max_pooling2d(conv8, pool_size=[2,2], strides=2, padding=\"same\")\n",
        "#conv9\n",
        "# Input Tensor Shape: [batch_size, 14, 14, 256]\n",
        "# Output Tensor Shape: [batch_size, 14, 14, 512]\n",
        "conv9 = tf.layers.conv2d(pool4, filters=512, kernel_size=[3,3], padding=\"same\", activation=tf.nn.relu)\n",
        "\n",
        "#pool5\n",
        "# Input Tensor Shape: [batch_size, 14, 14, 512]\n",
        "# Output Tensor Shape: [batch_size, 7, 7, 512]\n",
        "pool5 = tf.layers.max_pooling2d(conv9, pool_size=[2,2], strides=2, padding=\"same\")\n",
        "\n",
        "#dim = int(np.prod(pool5.get_shape()[1:])) #7*7*512\n",
        "#fcl = tf.reshape(pool5, shape=[-1, dim], name ='fc1')#[batch_size,7*7*512]\n",
        "# decoder\n",
        "\n",
        "# Input Tensor Shape: [batch_size, 7, 7, 512]\n",
        "# Output Tensor Shape: [batch_size, 14, 14, 512]\n",
        "net=tf.layers.conv2d_transpose(pool5,512,[3, 3],strides = 2,padding='SAME')\n",
        "\n",
        "# Input Tensor Shape: [batch_size, 7, 7, 512]\n",
        "# Output Tensor Shape: [batch_size, 28, 28, 256]\n",
        "net=tf.layers.conv2d_transpose(net,256,[3, 3],strides = 2,padding='SAME')\n",
        "\n",
        "# Input Tensor Shape: [batch_size, 28, 28, 128]\n",
        "# Output Tensor Shape: [batch_size, 224, 224, 128]\n",
        "net=tf.layers.conv2d_transpose(net,128,[3, 3],strides = 4,padding='SAME')\n",
        "\n",
        "# Input Tensor Shape: [batch_size, 224, 224, 128]\n",
        "# Output Tensor Shape: [batch_size, 224, 224, 64]\n",
        "net=tf.layers.conv2d_transpose(net,64,[3, 3],strides = 1,padding='SAME')\n",
        "\n",
        "# Input Tensor Shape: [batch_size, 224, 224, 64]\n",
        "# Output Tensor Shape: [batch_size, 224, 224, 32]\n",
        "net=tf.layers.conv2d_transpose(net,32,[3, 3],strides = 1, padding='SAME', activation = tf.nn.tanh)\n",
        "\n",
        "# Input Tensor Shape: [batch_size, 224, 224, 32]\n",
        "# Output Tensor Shape: [batch_size, 224, 224, 3]\n",
        "net=tf.layers.conv2d_transpose(net,3,[3, 3],strides = 1, padding='SAME', activation = tf.nn.tanh)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNzgCa05zB0d"
      },
      "outputs": [],
      "source": [
        "#normlizing output\n",
        "wmax = tf.reduce_max(net, axis=2, keepdims=True) # along width dimension\n",
        "output_max = tf.reduce_max(wmax, axis=1, keepdims=True) # along height dimension\n",
        "normalized_output = net / output_max\n",
        "alpha = 1.1\n",
        "loss = tf.reduce_mean( tf.square( (1.0/(alpha - y)) * (normalized_output - y) ))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JkQpeiENg4tD"
      },
      "outputs": [],
      "source": [
        "!unzip -qq train.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P-CIQbYmlE3j"
      },
      "outputs": [],
      "source": [
        "from datareader import DataReader\n",
        "train_images = DataReader('train')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FBu6qF1NS4I6"
      },
      "outputs": [],
      "source": [
        "## Optimize\n",
        "batch_size=10\n",
        "num_batches= train_images.num_batches_of_size(batch_size)\n",
        "learning_rate = 0.01\n",
        "n_epochs = 10\n",
        "loss = tf.reduce_mean(tf.square(net - y))\n",
        "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
        "train  = optimizer.minimize(loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "sPqqHoDRP0e_",
        "outputId": "86224585-a168-49c9-86a9-4534c1aebb46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch  0\n",
            "epoch 0 batch number 0    batch loss: 0.4297865629196167\n",
            "epoch 0 batch number 1    batch loss: 0.42161113023757935\n",
            "epoch 0 batch number 2    batch loss: 1.2245466709136963\n",
            "epoch 0 batch number 3    batch loss: 0.8615840673446655\n",
            "epoch 0 batch number 4    batch loss: 0.5458099842071533\n",
            "epoch 0 batch number 5    batch loss: 0.41062361001968384\n",
            "epoch 0 batch number 6    batch loss: 0.42317989468574524\n",
            "epoch 0 batch number 7    batch loss: 0.4313059151172638\n",
            "epoch 0 batch number 8    batch loss: 0.43355539441108704\n",
            "epoch 0 batch number 9    batch loss: 0.4634784758090973\n",
            "epoch 0 batch number 10    batch loss: 0.4412766098976135\n",
            "epoch 0 batch number 11    batch loss: 0.403820663690567\n",
            "epoch 0 batch number 12    batch loss: 0.4055498540401459\n",
            "epoch 0 batch number 13    batch loss: 0.41971203684806824\n",
            "epoch 0 batch number 14    batch loss: 0.41030338406562805\n",
            "epoch 0 batch number 15    batch loss: 0.39155012369155884\n",
            "epoch 0 batch number 16    batch loss: 0.4090840518474579\n",
            "epoch 0 batch number 17    batch loss: 0.3943786323070526\n",
            "epoch 0 batch number 18    batch loss: 0.4132366180419922\n",
            "epoch 0 batch number 19    batch loss: 0.40292054414749146\n",
            "epoch 0 batch number 20    batch loss: 0.3860904276371002\n",
            "epoch 0 batch number 21    batch loss: 0.3973841667175293\n",
            "epoch 0 batch number 22    batch loss: 0.3803690969944\n",
            "epoch 0 batch number 23    batch loss: 0.3974789083003998\n",
            "epoch 0 batch number 24    batch loss: 0.3723808825016022\n",
            "epoch 0 batch number 25    batch loss: 0.44412365555763245\n",
            "epoch 0 batch number 26    batch loss: 0.4420001208782196\n",
            "epoch 0 batch number 27    batch loss: 0.47563400864601135\n",
            "epoch 0 batch number 28    batch loss: 0.46859636902809143\n",
            "epoch 0 batch number 29    batch loss: 0.47589942812919617\n",
            "epoch 0 batch number 30    batch loss: 0.47300711274147034\n",
            "epoch 0 batch number 31    batch loss: 0.47283777594566345\n",
            "epoch 0 batch number 32    batch loss: 0.4910210967063904\n",
            "epoch 0 batch number 33    batch loss: 0.5081835389137268\n",
            "epoch 0 batch number 34    batch loss: 0.5261164307594299\n",
            "epoch 0 batch number 35    batch loss: 0.5394424200057983\n",
            "epoch 0 batch number 36    batch loss: 0.5611416697502136\n",
            "epoch 0 batch number 37    batch loss: 0.5661979913711548\n",
            "epoch 0 batch number 38    batch loss: 0.5318825244903564\n",
            "epoch 0 batch number 39    batch loss: 0.47590506076812744\n",
            "epoch 0 batch number 40    batch loss: 0.4640563428401947\n",
            "epoch 0 batch number 41    batch loss: 0.47198963165283203\n",
            "epoch 0 batch number 42    batch loss: 0.4452083706855774\n",
            "epoch 0 batch number 43    batch loss: 0.4434584379196167\n",
            "epoch 0 batch number 44    batch loss: 0.42838940024375916\n",
            "epoch 0 batch number 45    batch loss: 0.4029563069343567\n",
            "epoch 0 batch number 46    batch loss: 0.4044936001300812\n",
            "epoch 0 batch number 47    batch loss: 0.39559048414230347\n",
            "epoch 0 batch number 48    batch loss: 0.34182843565940857\n",
            "epoch 0 batch number 49    batch loss: 0.3555838465690613\n",
            "epoch 0 batch number 50    batch loss: 0.37690815329551697\n",
            "epoch 0 batch number 51    batch loss: 0.3662058413028717\n",
            "epoch 0 batch number 52    batch loss: 0.3446618318557739\n",
            "epoch 0 batch number 53    batch loss: 0.3998212218284607\n",
            "epoch 0 batch number 54    batch loss: 0.3482285141944885\n",
            "epoch 0 batch number 55    batch loss: 0.3439411520957947\n",
            "epoch 0 batch number 56    batch loss: 0.3732607960700989\n",
            "epoch 0 batch number 57    batch loss: 0.3254126012325287\n",
            "epoch 0 batch number 58    batch loss: 0.3594791293144226\n",
            "epoch 0 batch number 59    batch loss: 0.3378099203109741\n",
            "epoch 0 batch number 60    batch loss: 0.3319670557975769\n",
            "epoch 0 batch number 61    batch loss: 0.37413105368614197\n",
            "epoch 0 batch number 62    batch loss: 0.3300471901893616\n",
            "epoch 0 batch number 63    batch loss: 0.38067904114723206\n",
            "epoch 0 batch number 64    batch loss: 0.352067232131958\n",
            "epoch 0 batch number 65    batch loss: 0.32798004150390625\n",
            "epoch 0 batch number 66    batch loss: 0.35714730620384216\n",
            "epoch 0 batch number 67    batch loss: 0.330588161945343\n",
            "epoch 0 batch number 68    batch loss: 0.35682427883148193\n",
            "epoch 0 batch number 69    batch loss: 0.38739120960235596\n",
            "epoch 0 batch number 70    batch loss: 0.3336574137210846\n",
            "epoch 0 batch number 71    batch loss: 0.34535083174705505\n",
            "epoch 0 batch number 72    batch loss: 0.33007168769836426\n",
            "epoch 0 batch number 73    batch loss: 0.3214472532272339\n",
            "epoch 0 batch number 74    batch loss: 0.3377745747566223\n",
            "epoch 0 batch number 75    batch loss: 0.3137893080711365\n",
            "epoch 0 batch number 76    batch loss: 0.3320901393890381\n",
            "epoch 0 batch number 77    batch loss: 0.3293256163597107\n",
            "epoch 0 batch number 78    batch loss: 0.3066466152667999\n",
            "epoch 0 batch number 79    batch loss: 0.3220425248146057\n",
            "epoch 0 batch number 80    batch loss: 0.3116086721420288\n",
            "epoch 0 batch number 81    batch loss: 0.27206242084503174\n",
            "epoch 0 batch number 82    batch loss: 0.2612611651420593\n",
            "epoch 0 batch number 83    batch loss: 0.3298424780368805\n",
            "epoch 0 batch number 84    batch loss: 0.26986512541770935\n",
            "epoch 0 batch number 85    batch loss: 0.29842114448547363\n",
            "epoch 0 batch number 86    batch loss: 0.2922792434692383\n",
            "epoch 0 batch number 87    batch loss: 0.3372259736061096\n",
            "epoch 0 batch number 88    batch loss: 0.3254673182964325\n",
            "epoch 0 batch number 89    batch loss: 0.3458086848258972\n",
            "epoch 0 batch number 90    batch loss: 0.32825857400894165\n",
            "epoch 0 batch number 91    batch loss: 0.30192509293556213\n",
            "epoch 0 batch number 92    batch loss: 0.30821943283081055\n",
            "epoch 0 batch number 93    batch loss: 0.32328930497169495\n",
            "epoch 0 batch number 94    batch loss: 0.3294384479522705\n",
            "epoch 0 batch number 95    batch loss: 0.37434813380241394\n",
            "epoch 0 batch number 96    batch loss: 0.3278679847717285\n",
            "epoch 0 batch number 97    batch loss: 0.32379579544067383\n",
            "epoch 0 batch number 98    batch loss: 0.3377317786216736\n",
            "epoch 0 batch number 99    batch loss: 0.3359747529029846\n",
            " Average batches loss: 0.39987999200820923 \n",
            "epoch  1\n",
            "epoch 1 batch number 0    batch loss: 0.35660916566848755\n",
            "epoch 1 batch number 1    batch loss: 0.3223983347415924\n",
            "epoch 1 batch number 2    batch loss: 0.3038477599620819\n",
            "epoch 1 batch number 3    batch loss: 0.3667406439781189\n",
            "epoch 1 batch number 4    batch loss: 0.3052642345428467\n",
            "epoch 1 batch number 5    batch loss: 0.34280914068222046\n",
            "epoch 1 batch number 6    batch loss: 0.3089164197444916\n",
            "epoch 1 batch number 7    batch loss: 0.32262447476387024\n",
            "epoch 1 batch number 8    batch loss: 0.30008748173713684\n",
            "epoch 1 batch number 9    batch loss: 0.29389381408691406\n",
            "epoch 1 batch number 10    batch loss: 0.2948661148548126\n",
            "epoch 1 batch number 11    batch loss: 0.29937049746513367\n",
            "epoch 1 batch number 12    batch loss: 0.31083086133003235\n",
            "epoch 1 batch number 13    batch loss: 0.30014368891716003\n",
            "epoch 1 batch number 14    batch loss: 0.313226580619812\n",
            "epoch 1 batch number 15    batch loss: 0.2836717963218689\n",
            "epoch 1 batch number 16    batch loss: 0.2905717194080353\n",
            "epoch 1 batch number 17    batch loss: 0.2979288697242737\n",
            "epoch 1 batch number 18    batch loss: 0.2679358124732971\n",
            "epoch 1 batch number 19    batch loss: 0.2781071066856384\n",
            "epoch 1 batch number 20    batch loss: 0.24432453513145447\n",
            "epoch 1 batch number 21    batch loss: 0.2521878182888031\n",
            "epoch 1 batch number 22    batch loss: 0.23973575234413147\n",
            "epoch 1 batch number 23    batch loss: 0.22543905675411224\n",
            "epoch 1 batch number 24    batch loss: 0.2582043409347534\n",
            "epoch 1 batch number 25    batch loss: 0.24660632014274597\n",
            "epoch 1 batch number 26    batch loss: 0.2765066623687744\n",
            "epoch 1 batch number 27    batch loss: 0.2598594129085541\n",
            "epoch 1 batch number 28    batch loss: 0.2216055542230606\n",
            "epoch 1 batch number 29    batch loss: 0.2783445715904236\n",
            "epoch 1 batch number 30    batch loss: 0.2555890381336212\n",
            "epoch 1 batch number 31    batch loss: 0.26060083508491516\n",
            "epoch 1 batch number 32    batch loss: 0.2803994417190552\n",
            "epoch 1 batch number 33    batch loss: 0.26925361156463623\n",
            "epoch 1 batch number 34    batch loss: 0.2439901977777481\n",
            "epoch 1 batch number 35    batch loss: 0.2535161077976227\n",
            "epoch 1 batch number 36    batch loss: 0.2467675805091858\n",
            "epoch 1 batch number 37    batch loss: 0.24341687560081482\n",
            "epoch 1 batch number 38    batch loss: 0.2519805133342743\n",
            "epoch 1 batch number 39    batch loss: 0.254203736782074\n",
            "epoch 1 batch number 40    batch loss: 0.2107970118522644\n",
            "epoch 1 batch number 41    batch loss: 0.2953229546546936\n",
            "epoch 1 batch number 42    batch loss: 0.2213127315044403\n",
            "epoch 1 batch number 43    batch loss: 0.2708792984485626\n",
            "epoch 1 batch number 44    batch loss: 0.2766464352607727\n",
            "epoch 1 batch number 45    batch loss: 0.305803507566452\n",
            "epoch 1 batch number 46    batch loss: 0.29112136363983154\n",
            "epoch 1 batch number 47    batch loss: 0.29962393641471863\n",
            "epoch 1 batch number 48    batch loss: 0.26007503271102905\n",
            "epoch 1 batch number 49    batch loss: 0.2695886790752411\n",
            "epoch 1 batch number 50    batch loss: 0.21071301400661469\n",
            "epoch 1 batch number 51    batch loss: 0.3529157042503357\n",
            "epoch 1 batch number 52    batch loss: 0.22573810815811157\n",
            "epoch 1 batch number 53    batch loss: 0.26897260546684265\n",
            "epoch 1 batch number 54    batch loss: 0.2961098551750183\n",
            "epoch 1 batch number 55    batch loss: 0.27975061535835266\n",
            "epoch 1 batch number 56    batch loss: 0.28202545642852783\n",
            "epoch 1 batch number 57    batch loss: 0.30764463543891907\n",
            "epoch 1 batch number 58    batch loss: 0.28944432735443115\n",
            "epoch 1 batch number 59    batch loss: 0.2820783853530884\n",
            "epoch 1 batch number 60    batch loss: 0.2729184627532959\n",
            "epoch 1 batch number 61    batch loss: 0.2613746225833893\n",
            "epoch 1 batch number 62    batch loss: 0.2816343605518341\n",
            "epoch 1 batch number 63    batch loss: 0.2589368224143982\n",
            "epoch 1 batch number 64    batch loss: 0.2412784844636917\n",
            "epoch 1 batch number 65    batch loss: 0.26858460903167725\n",
            "epoch 1 batch number 66    batch loss: 0.27050894498825073\n",
            "epoch 1 batch number 67    batch loss: 0.3082798421382904\n",
            "epoch 1 batch number 68    batch loss: 0.26468709111213684\n",
            "epoch 1 batch number 69    batch loss: 0.23808421194553375\n",
            "epoch 1 batch number 70    batch loss: 0.2982802093029022\n",
            "epoch 1 batch number 71    batch loss: 0.24280358850955963\n",
            "epoch 1 batch number 72    batch loss: 0.2437555491924286\n",
            "epoch 1 batch number 73    batch loss: 0.26571401953697205\n",
            "epoch 1 batch number 74    batch loss: 0.26259294152259827\n",
            "epoch 1 batch number 75    batch loss: 0.24317561089992523\n",
            "epoch 1 batch number 76    batch loss: 0.2253776341676712\n",
            "epoch 1 batch number 77    batch loss: 0.28202369809150696\n",
            "epoch 1 batch number 78    batch loss: 0.21306289732456207\n",
            "epoch 1 batch number 79    batch loss: 0.22517907619476318\n",
            "epoch 1 batch number 80    batch loss: 0.22342762351036072\n",
            "epoch 1 batch number 81    batch loss: 0.2323232889175415\n",
            "epoch 1 batch number 82    batch loss: 0.2157994657754898\n",
            "epoch 1 batch number 83    batch loss: 0.24156655371189117\n",
            "epoch 1 batch number 84    batch loss: 0.20878125727176666\n",
            "epoch 1 batch number 85    batch loss: 0.23145939409732819\n",
            "epoch 1 batch number 86    batch loss: 0.24273593723773956\n",
            "epoch 1 batch number 87    batch loss: 0.19717232882976532\n",
            "epoch 1 batch number 88    batch loss: 0.22773590683937073\n",
            "epoch 1 batch number 89    batch loss: 0.1851278692483902\n",
            "epoch 1 batch number 90    batch loss: 0.21717463433742523\n",
            "epoch 1 batch number 91    batch loss: 0.20988748967647552\n",
            "epoch 1 batch number 92    batch loss: 0.23414473235607147\n",
            "epoch 1 batch number 93    batch loss: 0.21332545578479767\n",
            "epoch 1 batch number 94    batch loss: 0.20854492485523224\n",
            "epoch 1 batch number 95    batch loss: 0.20906417071819305\n",
            "epoch 1 batch number 96    batch loss: 0.21247442066669464\n",
            "epoch 1 batch number 97    batch loss: 0.21589532494544983\n",
            "epoch 1 batch number 98    batch loss: 0.2249496430158615\n",
            "epoch 1 batch number 99    batch loss: 0.23666509985923767\n",
            " Average batches loss: 0.26275449991226196 \n",
            "epoch  2\n",
            "epoch 2 batch number 0    batch loss: 0.22462838888168335\n",
            "epoch 2 batch number 1    batch loss: 0.24551591277122498\n",
            "epoch 2 batch number 2    batch loss: 0.2407621443271637\n",
            "epoch 2 batch number 3    batch loss: 0.22968393564224243\n",
            "epoch 2 batch number 4    batch loss: 0.26821163296699524\n",
            "epoch 2 batch number 5    batch loss: 0.2276897430419922\n",
            "epoch 2 batch number 6    batch loss: 0.249550461769104\n",
            "epoch 2 batch number 7    batch loss: 0.2414013147354126\n",
            "epoch 2 batch number 8    batch loss: 0.2392963469028473\n",
            "epoch 2 batch number 9    batch loss: 0.2331087440252304\n",
            "epoch 2 batch number 10    batch loss: 0.2403731793165207\n",
            "epoch 2 batch number 11    batch loss: 0.22049155831336975\n",
            "epoch 2 batch number 12    batch loss: 0.22796519100666046\n",
            "epoch 2 batch number 13    batch loss: 0.21011516451835632\n",
            "epoch 2 batch number 14    batch loss: 0.2312912940979004\n",
            "epoch 2 batch number 15    batch loss: 0.21851606667041779\n",
            "epoch 2 batch number 16    batch loss: 0.2727714776992798\n",
            "epoch 2 batch number 17    batch loss: 0.2730265259742737\n",
            "epoch 2 batch number 18    batch loss: 0.28988561034202576\n",
            "epoch 2 batch number 19    batch loss: 0.26274603605270386\n",
            "epoch 2 batch number 20    batch loss: 0.2935149073600769\n",
            "epoch 2 batch number 21    batch loss: 0.28535062074661255\n",
            "epoch 2 batch number 22    batch loss: 0.2988722324371338\n",
            "epoch 2 batch number 23    batch loss: 0.2909117043018341\n",
            "epoch 2 batch number 24    batch loss: 0.30361536145210266\n",
            "epoch 2 batch number 25    batch loss: 0.28297537565231323\n",
            "epoch 2 batch number 26    batch loss: 0.2976074516773224\n",
            "epoch 2 batch number 27    batch loss: 0.29723572731018066\n",
            "epoch 2 batch number 28    batch loss: 0.28215813636779785\n",
            "epoch 2 batch number 29    batch loss: 0.27705883979797363\n",
            "epoch 2 batch number 30    batch loss: 0.2761518657207489\n",
            "epoch 2 batch number 31    batch loss: 0.2927219867706299\n",
            "epoch 2 batch number 32    batch loss: 0.2659202516078949\n",
            "epoch 2 batch number 33    batch loss: 0.27275359630584717\n",
            "epoch 2 batch number 34    batch loss: 0.276406854391098\n",
            "epoch 2 batch number 35    batch loss: 0.2774655520915985\n",
            "epoch 2 batch number 36    batch loss: 0.2748059332370758\n",
            "epoch 2 batch number 37    batch loss: 0.25963619351387024\n",
            "epoch 2 batch number 38    batch loss: 0.2679182291030884\n",
            "epoch 2 batch number 39    batch loss: 0.26062625646591187\n",
            "epoch 2 batch number 40    batch loss: 0.2818900942802429\n",
            "epoch 2 batch number 41    batch loss: 0.2659701406955719\n",
            "epoch 2 batch number 42    batch loss: 0.26464101672172546\n",
            "epoch 2 batch number 43    batch loss: 0.2663184404373169\n",
            "epoch 2 batch number 44    batch loss: 0.2642080783843994\n",
            "epoch 2 batch number 45    batch loss: 0.2595314383506775\n",
            "epoch 2 batch number 46    batch loss: 0.252663254737854\n",
            "epoch 2 batch number 47    batch loss: 0.264944463968277\n",
            "epoch 2 batch number 48    batch loss: 0.2424253672361374\n",
            "epoch 2 batch number 49    batch loss: 0.24239522218704224\n",
            "epoch 2 batch number 50    batch loss: 0.2580733597278595\n",
            "epoch 2 batch number 51    batch loss: 0.24830903112888336\n",
            "epoch 2 batch number 52    batch loss: 0.24941858649253845\n",
            "epoch 2 batch number 53    batch loss: 0.23358967900276184\n",
            "epoch 2 batch number 54    batch loss: 0.22195260226726532\n",
            "epoch 2 batch number 55    batch loss: 0.2483023852109909\n",
            "epoch 2 batch number 56    batch loss: 0.2282615602016449\n",
            "epoch 2 batch number 57    batch loss: 0.24263089895248413\n",
            "epoch 2 batch number 58    batch loss: 0.23075857758522034\n",
            "epoch 2 batch number 59    batch loss: 0.2269553691148758\n",
            "epoch 2 batch number 60    batch loss: 0.22962889075279236\n",
            "epoch 2 batch number 61    batch loss: 0.24471311271190643\n",
            "epoch 2 batch number 62    batch loss: 0.24588562548160553\n",
            "epoch 2 batch number 63    batch loss: 0.2454938143491745\n",
            "epoch 2 batch number 64    batch loss: 0.2359727919101715\n",
            "epoch 2 batch number 65    batch loss: 0.2310509979724884\n",
            "epoch 2 batch number 66    batch loss: 0.22712348401546478\n",
            "epoch 2 batch number 67    batch loss: 0.23048460483551025\n",
            "epoch 2 batch number 68    batch loss: 0.22076834738254547\n",
            "epoch 2 batch number 69    batch loss: 0.22530241310596466\n",
            "epoch 2 batch number 70    batch loss: 0.23243281245231628\n",
            "epoch 2 batch number 71    batch loss: 0.22732196748256683\n",
            "epoch 2 batch number 72    batch loss: 0.25416457653045654\n",
            "epoch 2 batch number 73    batch loss: 0.2662690281867981\n",
            "epoch 2 batch number 74    batch loss: 0.2747526168823242\n",
            "epoch 2 batch number 75    batch loss: 0.2754557430744171\n",
            "epoch 2 batch number 76    batch loss: 0.2896687090396881\n",
            "epoch 2 batch number 77    batch loss: 0.30242061614990234\n",
            "epoch 2 batch number 78    batch loss: 0.30635780096054077\n",
            "epoch 2 batch number 79    batch loss: 0.25856709480285645\n",
            "epoch 2 batch number 80    batch loss: 0.2640562355518341\n",
            "epoch 2 batch number 81    batch loss: 0.28655412793159485\n",
            "epoch 2 batch number 82    batch loss: 0.28904449939727783\n",
            "epoch 2 batch number 83    batch loss: 0.2631414830684662\n",
            "epoch 2 batch number 84    batch loss: 0.26198863983154297\n",
            "epoch 2 batch number 85    batch loss: 0.27601566910743713\n",
            "epoch 2 batch number 86    batch loss: 0.27862757444381714\n",
            "epoch 2 batch number 87    batch loss: 0.23810960352420807\n",
            "epoch 2 batch number 88    batch loss: 0.25048956274986267\n",
            "epoch 2 batch number 89    batch loss: 0.2609405219554901\n",
            "epoch 2 batch number 90    batch loss: 0.25599735975265503\n",
            "epoch 2 batch number 91    batch loss: 0.2421981692314148\n",
            "epoch 2 batch number 92    batch loss: 0.23683959245681763\n",
            "epoch 2 batch number 93    batch loss: 0.2519734501838684\n",
            "epoch 2 batch number 94    batch loss: 0.23913522064685822\n",
            "epoch 2 batch number 95    batch loss: 0.24487179517745972\n",
            "epoch 2 batch number 96    batch loss: 0.2257707417011261\n",
            "epoch 2 batch number 97    batch loss: 0.22390377521514893\n",
            "epoch 2 batch number 98    batch loss: 0.23525157570838928\n",
            "epoch 2 batch number 99    batch loss: 0.23371893167495728\n",
            " Average batches loss: 0.2555643916130066 \n",
            "epoch  3\n",
            "epoch 3 batch number 0    batch loss: 0.22344784438610077\n",
            "epoch 3 batch number 1    batch loss: 0.21573513746261597\n",
            "epoch 3 batch number 2    batch loss: 0.2133423238992691\n",
            "epoch 3 batch number 3    batch loss: 0.21531587839126587\n",
            "epoch 3 batch number 4    batch loss: 0.21999678015708923\n",
            "epoch 3 batch number 5    batch loss: 0.22554346919059753\n",
            "epoch 3 batch number 6    batch loss: 0.23351481556892395\n",
            "epoch 3 batch number 7    batch loss: 0.23532907664775848\n",
            "epoch 3 batch number 8    batch loss: 0.23596766591072083\n",
            "epoch 3 batch number 9    batch loss: 0.20512594282627106\n",
            "epoch 3 batch number 10    batch loss: 0.2139812856912613\n",
            "epoch 3 batch number 11    batch loss: 0.21365123987197876\n",
            "epoch 3 batch number 12    batch loss: 0.22826439142227173\n",
            "epoch 3 batch number 13    batch loss: 0.22428281605243683\n",
            "epoch 3 batch number 14    batch loss: 0.23155994713306427\n",
            "epoch 3 batch number 15    batch loss: 0.22544381022453308\n",
            "epoch 3 batch number 16    batch loss: 0.23010867834091187\n",
            "epoch 3 batch number 17    batch loss: 0.22911302745342255\n",
            "epoch 3 batch number 18    batch loss: 0.2194301038980484\n",
            "epoch 3 batch number 19    batch loss: 0.20633606612682343\n",
            "epoch 3 batch number 20    batch loss: 0.19769079983234406\n",
            "epoch 3 batch number 21    batch loss: 0.2236754596233368\n",
            "epoch 3 batch number 22    batch loss: 0.2109331339597702\n",
            "epoch 3 batch number 23    batch loss: 0.21336442232131958\n",
            "epoch 3 batch number 24    batch loss: 0.2289619743824005\n",
            "epoch 3 batch number 25    batch loss: 0.22607886791229248\n",
            "epoch 3 batch number 26    batch loss: 0.20880722999572754\n",
            "epoch 3 batch number 27    batch loss: 0.20636197924613953\n",
            "epoch 3 batch number 28    batch loss: 0.2101777195930481\n",
            "epoch 3 batch number 29    batch loss: 0.2075892835855484\n",
            "epoch 3 batch number 30    batch loss: 0.21011468768119812\n",
            "epoch 3 batch number 31    batch loss: 0.2025069296360016\n",
            "epoch 3 batch number 32    batch loss: 0.1972259283065796\n",
            "epoch 3 batch number 33    batch loss: 0.19685089588165283\n",
            "epoch 3 batch number 34    batch loss: 0.2056911289691925\n",
            "epoch 3 batch number 35    batch loss: 0.21220354735851288\n",
            "epoch 3 batch number 36    batch loss: 0.19784203171730042\n",
            "epoch 3 batch number 37    batch loss: 0.20869319140911102\n",
            "epoch 3 batch number 38    batch loss: 0.20503008365631104\n",
            "epoch 3 batch number 39    batch loss: 0.21303914487361908\n",
            "epoch 3 batch number 40    batch loss: 0.20478785037994385\n",
            "epoch 3 batch number 41    batch loss: 0.18066158890724182\n",
            "epoch 3 batch number 42    batch loss: 0.2058665156364441\n",
            "epoch 3 batch number 43    batch loss: 0.2030339241027832\n",
            "epoch 3 batch number 44    batch loss: 0.21507446467876434\n",
            "epoch 3 batch number 45    batch loss: 0.20770135521888733\n",
            "epoch 3 batch number 46    batch loss: 0.1820581555366516\n",
            "epoch 3 batch number 47    batch loss: 0.20533928275108337\n",
            "epoch 3 batch number 48    batch loss: 0.18982024490833282\n",
            "epoch 3 batch number 49    batch loss: 0.1908702552318573\n",
            "epoch 3 batch number 50    batch loss: 0.19677317142486572\n",
            "epoch 3 batch number 51    batch loss: 0.2021927386522293\n",
            "epoch 3 batch number 52    batch loss: 0.19718733429908752\n",
            "epoch 3 batch number 53    batch loss: 0.20491673052310944\n",
            "epoch 3 batch number 54    batch loss: 0.1841459721326828\n",
            "epoch 3 batch number 55    batch loss: 0.20208169519901276\n",
            "epoch 3 batch number 56    batch loss: 0.19378992915153503\n",
            "epoch 3 batch number 57    batch loss: 0.2067328840494156\n",
            "epoch 3 batch number 58    batch loss: 0.20198841392993927\n",
            "epoch 3 batch number 59    batch loss: 0.2009970247745514\n",
            "epoch 3 batch number 60    batch loss: 0.195706307888031\n",
            "epoch 3 batch number 61    batch loss: 0.19506163895130157\n",
            "epoch 3 batch number 62    batch loss: 0.2143966555595398\n",
            "epoch 3 batch number 63    batch loss: 0.20218466222286224\n",
            "epoch 3 batch number 64    batch loss: 0.20857951045036316\n",
            "epoch 3 batch number 65    batch loss: 0.1981995850801468\n",
            "epoch 3 batch number 66    batch loss: 0.19043812155723572\n",
            "epoch 3 batch number 67    batch loss: 0.17927397787570953\n",
            "epoch 3 batch number 68    batch loss: 0.19719909131526947\n",
            "epoch 3 batch number 69    batch loss: 0.20944736897945404\n",
            "epoch 3 batch number 70    batch loss: 0.20144076645374298\n",
            "epoch 3 batch number 71    batch loss: 0.1985252946615219\n",
            "epoch 3 batch number 72    batch loss: 0.18877403438091278\n",
            "epoch 3 batch number 73    batch loss: 0.19102366268634796\n",
            "epoch 3 batch number 74    batch loss: 0.19793617725372314\n",
            "epoch 3 batch number 75    batch loss: 0.21128036081790924\n",
            "epoch 3 batch number 76    batch loss: 0.21176327764987946\n",
            "epoch 3 batch number 77    batch loss: 0.20449939370155334\n",
            "epoch 3 batch number 78    batch loss: 0.19525955617427826\n",
            "epoch 3 batch number 79    batch loss: 0.2022322416305542\n",
            "epoch 3 batch number 80    batch loss: 0.19583062827587128\n",
            "epoch 3 batch number 81    batch loss: 0.19372878968715668\n",
            "epoch 3 batch number 82    batch loss: 0.19042183458805084\n",
            "epoch 3 batch number 83    batch loss: 0.1991785615682602\n",
            "epoch 3 batch number 84    batch loss: 0.18852102756500244\n",
            "epoch 3 batch number 85    batch loss: 0.19661292433738708\n",
            "epoch 3 batch number 86    batch loss: 0.21285408735275269\n",
            "epoch 3 batch number 87    batch loss: 0.2112230509519577\n",
            "epoch 3 batch number 88    batch loss: 0.1884627342224121\n",
            "epoch 3 batch number 89    batch loss: 0.19339679181575775\n",
            "epoch 3 batch number 90    batch loss: 0.19091902673244476\n",
            "epoch 3 batch number 91    batch loss: 0.19653622806072235\n",
            "epoch 3 batch number 92    batch loss: 0.18410378694534302\n",
            "epoch 3 batch number 93    batch loss: 0.19997753202915192\n",
            "epoch 3 batch number 94    batch loss: 0.18728035688400269\n",
            "epoch 3 batch number 95    batch loss: 0.2032088339328766\n",
            "epoch 3 batch number 96    batch loss: 0.1997770518064499\n",
            "epoch 3 batch number 97    batch loss: 0.20252995193004608\n",
            "epoch 3 batch number 98    batch loss: 0.19181127846240997\n",
            "epoch 3 batch number 99    batch loss: 0.18367211520671844\n",
            " Average batches loss: 0.2050761729478836 \n",
            "epoch  4\n",
            "epoch 4 batch number 0    batch loss: 0.20009061694145203\n",
            "epoch 4 batch number 1    batch loss: 0.1917547583580017\n",
            "epoch 4 batch number 2    batch loss: 0.1908472776412964\n",
            "epoch 4 batch number 3    batch loss: 0.19246883690357208\n",
            "epoch 4 batch number 4    batch loss: 0.19407954812049866\n",
            "epoch 4 batch number 5    batch loss: 0.1836296170949936\n",
            "epoch 4 batch number 6    batch loss: 0.18717578053474426\n",
            "epoch 4 batch number 7    batch loss: 0.19320906698703766\n",
            "epoch 4 batch number 8    batch loss: 0.19819244742393494\n",
            "epoch 4 batch number 9    batch loss: 0.20465773344039917\n",
            "epoch 4 batch number 10    batch loss: 0.19013801217079163\n",
            "epoch 4 batch number 11    batch loss: 0.1867673248052597\n",
            "epoch 4 batch number 12    batch loss: 0.18020018935203552\n",
            "epoch 4 batch number 13    batch loss: 0.19513504207134247\n",
            "epoch 4 batch number 14    batch loss: 0.18364901840686798\n",
            "epoch 4 batch number 15    batch loss: 0.18844544887542725\n",
            "epoch 4 batch number 16    batch loss: 0.18931229412555695\n",
            "epoch 4 batch number 17    batch loss: 0.19120799005031586\n",
            "epoch 4 batch number 18    batch loss: 0.2039511799812317\n",
            "epoch 4 batch number 19    batch loss: 0.17290151119232178\n",
            "epoch 4 batch number 20    batch loss: 0.20616455376148224\n",
            "epoch 4 batch number 21    batch loss: 0.18945395946502686\n",
            "epoch 4 batch number 22    batch loss: 0.2019032984972\n",
            "epoch 4 batch number 23    batch loss: 0.19215941429138184\n",
            "epoch 4 batch number 24    batch loss: 0.19191375374794006\n",
            "epoch 4 batch number 25    batch loss: 0.1933717429637909\n",
            "epoch 4 batch number 26    batch loss: 0.18543732166290283\n",
            "epoch 4 batch number 27    batch loss: 0.1966010481119156\n",
            "epoch 4 batch number 28    batch loss: 0.19248341023921967\n",
            "epoch 4 batch number 29    batch loss: 0.18810206651687622\n",
            "epoch 4 batch number 30    batch loss: 0.2080429047346115\n",
            "epoch 4 batch number 31    batch loss: 0.19558997452259064\n",
            "epoch 4 batch number 32    batch loss: 0.19211770594120026\n",
            "epoch 4 batch number 33    batch loss: 0.20587152242660522\n",
            "epoch 4 batch number 34    batch loss: 0.2032422572374344\n",
            "epoch 4 batch number 35    batch loss: 0.18492227792739868\n",
            "epoch 4 batch number 36    batch loss: 0.20039543509483337\n",
            "epoch 4 batch number 37    batch loss: 0.1953454613685608\n",
            "epoch 4 batch number 38    batch loss: 0.18673519790172577\n",
            "epoch 4 batch number 39    batch loss: 0.19831469655036926\n",
            "epoch 4 batch number 40    batch loss: 0.18836762011051178\n",
            "epoch 4 batch number 41    batch loss: 0.19773398339748383\n",
            "epoch 4 batch number 42    batch loss: 0.18837936222553253\n",
            "epoch 4 batch number 43    batch loss: 0.19782063364982605\n",
            "epoch 4 batch number 44    batch loss: 0.19056765735149384\n",
            "epoch 4 batch number 45    batch loss: 0.18789444863796234\n",
            "epoch 4 batch number 46    batch loss: 0.18726769089698792\n",
            "epoch 4 batch number 47    batch loss: 0.18815943598747253\n",
            "epoch 4 batch number 48    batch loss: 0.19191795587539673\n",
            "epoch 4 batch number 49    batch loss: 0.20183159410953522\n",
            "epoch 4 batch number 50    batch loss: 0.19535157084465027\n",
            "epoch 4 batch number 51    batch loss: 0.1957702487707138\n",
            "epoch 4 batch number 52    batch loss: 0.2000613659620285\n",
            "epoch 4 batch number 53    batch loss: 0.18034838140010834\n",
            "epoch 4 batch number 54    batch loss: 0.20633701980113983\n",
            "epoch 4 batch number 55    batch loss: 0.18385086953639984\n",
            "epoch 4 batch number 56    batch loss: 0.1940525621175766\n",
            "epoch 4 batch number 57    batch loss: 0.17810389399528503\n",
            "epoch 4 batch number 58    batch loss: 0.1822560876607895\n",
            "epoch 4 batch number 59    batch loss: 0.18523719906806946\n",
            "epoch 4 batch number 60    batch loss: 0.17148122191429138\n",
            "epoch 4 batch number 61    batch loss: 0.18954810500144958\n",
            "epoch 4 batch number 62    batch loss: 0.2147434949874878\n",
            "epoch 4 batch number 63    batch loss: 0.19044652581214905\n",
            "epoch 4 batch number 64    batch loss: 0.17597992718219757\n",
            "epoch 4 batch number 65    batch loss: 0.20432868599891663\n",
            "epoch 4 batch number 66    batch loss: 0.1788521558046341\n",
            "epoch 4 batch number 67    batch loss: 0.19235312938690186\n",
            "epoch 4 batch number 68    batch loss: 0.20862682163715363\n",
            "epoch 4 batch number 69    batch loss: 0.17164313793182373\n",
            "epoch 4 batch number 70    batch loss: 0.17523103952407837\n",
            "epoch 4 batch number 71    batch loss: 0.2019743025302887\n",
            "epoch 4 batch number 72    batch loss: 0.18713387846946716\n",
            "epoch 4 batch number 73    batch loss: 0.19935423135757446\n",
            "epoch 4 batch number 74    batch loss: 0.1800866574048996\n",
            "epoch 4 batch number 75    batch loss: 0.1974736601114273\n",
            "epoch 4 batch number 76    batch loss: 0.16715146601200104\n",
            "epoch 4 batch number 77    batch loss: 0.20750965178012848\n",
            "epoch 4 batch number 78    batch loss: 0.19881822168827057\n",
            "epoch 4 batch number 79    batch loss: 0.19997677206993103\n",
            "epoch 4 batch number 80    batch loss: 0.19797919690608978\n",
            "epoch 4 batch number 81    batch loss: 0.1975642442703247\n",
            "epoch 4 batch number 82    batch loss: 0.1835993081331253\n",
            "epoch 4 batch number 83    batch loss: 0.1825999617576599\n",
            "epoch 4 batch number 84    batch loss: 0.18451401591300964\n",
            "epoch 4 batch number 85    batch loss: 0.19395670294761658\n",
            "epoch 4 batch number 86    batch loss: 0.19351615011692047\n",
            "epoch 4 batch number 87    batch loss: 0.19550442695617676\n",
            "epoch 4 batch number 88    batch loss: 0.19271591305732727\n",
            "epoch 4 batch number 89    batch loss: 0.1901932954788208\n",
            "epoch 4 batch number 90    batch loss: 0.18852655589580536\n",
            "epoch 4 batch number 91    batch loss: 0.19327622652053833\n",
            "epoch 4 batch number 92    batch loss: 0.18804731965065002\n",
            "epoch 4 batch number 93    batch loss: 0.1976964771747589\n",
            "epoch 4 batch number 94    batch loss: 0.18713702261447906\n",
            "epoch 4 batch number 95    batch loss: 0.1954701691865921\n",
            "epoch 4 batch number 96    batch loss: 0.18354156613349915\n",
            "epoch 4 batch number 97    batch loss: 0.19728747010231018\n",
            "epoch 4 batch number 98    batch loss: 0.19857238233089447\n",
            "epoch 4 batch number 99    batch loss: 0.19073796272277832\n",
            " Average batches loss: 0.19192439317703247 \n",
            "epoch  5\n",
            "epoch 5 batch number 0    batch loss: 0.17924001812934875\n",
            "epoch 5 batch number 1    batch loss: 0.19081518054008484\n",
            "epoch 5 batch number 2    batch loss: 0.19242827594280243\n",
            "epoch 5 batch number 3    batch loss: 0.16001787781715393\n",
            "epoch 5 batch number 4    batch loss: 0.20142479240894318\n",
            "epoch 5 batch number 5    batch loss: 0.1955663561820984\n",
            "epoch 5 batch number 6    batch loss: 0.18361686170101166\n",
            "epoch 5 batch number 7    batch loss: 0.18501578271389008\n",
            "epoch 5 batch number 8    batch loss: 0.2000972479581833\n",
            "epoch 5 batch number 9    batch loss: 0.1972256600856781\n",
            "epoch 5 batch number 10    batch loss: 0.19874143600463867\n",
            "epoch 5 batch number 11    batch loss: 0.19897256791591644\n",
            "epoch 5 batch number 12    batch loss: 0.17777080833911896\n",
            "epoch 5 batch number 13    batch loss: 0.19050227105617523\n",
            "epoch 5 batch number 14    batch loss: 0.19655491411685944\n",
            "epoch 5 batch number 15    batch loss: 0.20061151683330536\n",
            "epoch 5 batch number 16    batch loss: 0.19527605175971985\n",
            "epoch 5 batch number 17    batch loss: 0.19012382626533508\n",
            "epoch 5 batch number 18    batch loss: 0.20104141533374786\n",
            "epoch 5 batch number 19    batch loss: 0.19077442586421967\n",
            "epoch 5 batch number 20    batch loss: 0.19132694602012634\n",
            "epoch 5 batch number 21    batch loss: 0.20013807713985443\n",
            "epoch 5 batch number 22    batch loss: 0.2024727761745453\n",
            "epoch 5 batch number 23    batch loss: 0.19671136140823364\n",
            "epoch 5 batch number 24    batch loss: 0.20180203020572662\n",
            "epoch 5 batch number 25    batch loss: 0.19542090594768524\n",
            "epoch 5 batch number 26    batch loss: 0.20060844719409943\n",
            "epoch 5 batch number 27    batch loss: 0.19341254234313965\n",
            "epoch 5 batch number 28    batch loss: 0.19214971363544464\n",
            "epoch 5 batch number 29    batch loss: 0.2027483880519867\n",
            "epoch 5 batch number 30    batch loss: 0.1794472187757492\n",
            "epoch 5 batch number 31    batch loss: 0.20429162681102753\n",
            "epoch 5 batch number 32    batch loss: 0.1978573352098465\n",
            "epoch 5 batch number 33    batch loss: 0.1874726414680481\n",
            "epoch 5 batch number 34    batch loss: 0.17656287550926208\n",
            "epoch 5 batch number 35    batch loss: 0.19159916043281555\n",
            "epoch 5 batch number 36    batch loss: 0.1910620629787445\n",
            "epoch 5 batch number 37    batch loss: 0.18796440958976746\n",
            "epoch 5 batch number 38    batch loss: 0.1946842074394226\n",
            "epoch 5 batch number 39    batch loss: 0.19403201341629028\n",
            "epoch 5 batch number 40    batch loss: 0.19152863323688507\n",
            "epoch 5 batch number 41    batch loss: 0.17821858823299408\n",
            "epoch 5 batch number 42    batch loss: 0.19449950754642487\n",
            "epoch 5 batch number 43    batch loss: 0.19500398635864258\n",
            "epoch 5 batch number 44    batch loss: 0.18233539164066315\n",
            "epoch 5 batch number 45    batch loss: 0.19543161988258362\n",
            "epoch 5 batch number 46    batch loss: 0.19860965013504028\n",
            "epoch 5 batch number 47    batch loss: 0.1805954873561859\n",
            "epoch 5 batch number 48    batch loss: 0.17785918712615967\n",
            "epoch 5 batch number 49    batch loss: 0.19715633988380432\n",
            "epoch 5 batch number 50    batch loss: 0.18776452541351318\n",
            "epoch 5 batch number 51    batch loss: 0.19298504292964935\n",
            "epoch 5 batch number 52    batch loss: 0.18256200850009918\n",
            "epoch 5 batch number 53    batch loss: 0.19114911556243896\n",
            "epoch 5 batch number 54    batch loss: 0.19170382618904114\n",
            "epoch 5 batch number 55    batch loss: 0.18738527595996857\n",
            "epoch 5 batch number 56    batch loss: 0.19842688739299774\n",
            "epoch 5 batch number 57    batch loss: 0.1872321367263794\n",
            "epoch 5 batch number 58    batch loss: 0.20798692107200623\n",
            "epoch 5 batch number 59    batch loss: 0.1860886514186859\n",
            "epoch 5 batch number 60    batch loss: 0.1838124394416809\n",
            "epoch 5 batch number 61    batch loss: 0.20061422884464264\n",
            "epoch 5 batch number 62    batch loss: 0.19713567197322845\n",
            "epoch 5 batch number 63    batch loss: 0.20696735382080078\n",
            "epoch 5 batch number 64    batch loss: 0.1998571753501892\n",
            "epoch 5 batch number 65    batch loss: 0.1881655603647232\n",
            "epoch 5 batch number 66    batch loss: 0.1908368021249771\n",
            "epoch 5 batch number 67    batch loss: 0.19771678745746613\n",
            "epoch 5 batch number 68    batch loss: 0.2116926908493042\n",
            "epoch 5 batch number 69    batch loss: 0.18656906485557556\n",
            "epoch 5 batch number 70    batch loss: 0.1868637353181839\n",
            "epoch 5 batch number 71    batch loss: 0.203056201338768\n",
            "epoch 5 batch number 72    batch loss: 0.1969735324382782\n",
            "epoch 5 batch number 73    batch loss: 0.18088142573833466\n",
            "epoch 5 batch number 74    batch loss: 0.19541603326797485\n",
            "epoch 5 batch number 75    batch loss: 0.1756695806980133\n",
            "epoch 5 batch number 76    batch loss: 0.19511017203330994\n",
            "epoch 5 batch number 77    batch loss: 0.1911677122116089\n",
            "epoch 5 batch number 78    batch loss: 0.1932266801595688\n",
            "epoch 5 batch number 79    batch loss: 0.19334349036216736\n",
            "epoch 5 batch number 80    batch loss: 0.17718467116355896\n",
            "epoch 5 batch number 81    batch loss: 0.1980864405632019\n",
            "epoch 5 batch number 82    batch loss: 0.19031763076782227\n",
            "epoch 5 batch number 83    batch loss: 0.1872127205133438\n",
            "epoch 5 batch number 84    batch loss: 0.2006739228963852\n",
            "epoch 5 batch number 85    batch loss: 0.19465142488479614\n",
            "epoch 5 batch number 86    batch loss: 0.20388449728488922\n",
            "epoch 5 batch number 87    batch loss: 0.18609094619750977\n",
            "epoch 5 batch number 88    batch loss: 0.18354466557502747\n",
            "epoch 5 batch number 89    batch loss: 0.19597718119621277\n",
            "epoch 5 batch number 90    batch loss: 0.1799507439136505\n",
            "epoch 5 batch number 91    batch loss: 0.18669064342975616\n",
            "epoch 5 batch number 92    batch loss: 0.17647762596607208\n",
            "epoch 5 batch number 93    batch loss: 0.20368576049804688\n",
            "epoch 5 batch number 94    batch loss: 0.19097056984901428\n",
            "epoch 5 batch number 95    batch loss: 0.1985006481409073\n",
            "epoch 5 batch number 96    batch loss: 0.1961166113615036\n",
            "epoch 5 batch number 97    batch loss: 0.18776431679725647\n",
            "epoch 5 batch number 98    batch loss: 0.18492665886878967\n",
            "epoch 5 batch number 99    batch loss: 0.1951843500137329\n",
            " Average batches loss: 0.1920507550239563 \n",
            "epoch  6\n",
            "epoch 6 batch number 0    batch loss: 0.19155989587306976\n",
            "epoch 6 batch number 1    batch loss: 0.1728615015745163\n",
            "epoch 6 batch number 2    batch loss: 0.20253166556358337\n",
            "epoch 6 batch number 3    batch loss: 0.19521142542362213\n",
            "epoch 6 batch number 4    batch loss: 0.178024023771286\n",
            "epoch 6 batch number 5    batch loss: 0.18923233449459076\n",
            "epoch 6 batch number 6    batch loss: 0.20032952725887299\n",
            "epoch 6 batch number 7    batch loss: 0.20994436740875244\n",
            "epoch 6 batch number 8    batch loss: 0.20217251777648926\n",
            "epoch 6 batch number 9    batch loss: 0.2040315866470337\n",
            "epoch 6 batch number 10    batch loss: 0.1858411282300949\n",
            "epoch 6 batch number 11    batch loss: 0.17795205116271973\n",
            "epoch 6 batch number 12    batch loss: 0.18324606120586395\n",
            "epoch 6 batch number 13    batch loss: 0.20303626358509064\n",
            "epoch 6 batch number 14    batch loss: 0.19824351370334625\n"
          ]
        }
      ],
      "source": [
        "init = tf.global_variables_initializer()\n",
        "averageloss=[]\n",
        "with tf.Session() as sess:\n",
        "    sess.run(init)\n",
        "    for epoch in range(n_epochs):\n",
        "        print('epoch ',epoch)\n",
        "        DLOSS=[]\n",
        "        for i in range(num_batches):\n",
        "          images, blur, _ = train_images.get_batch(batch_size)\n",
        "          batch_loss = sess.run([loss, train], feed_dict={x: images, y: blur})\n",
        "          DLOSS.append(batch_loss[0])\n",
        "          print('epoch {} batch number {}    batch loss: {}'.format(epoch, i ,batch_loss[0]))\n",
        "        MeanDloss=np.mean(DLOSS)\n",
        "        averageloss.append(np.mean(DLOSS))\n",
        "        print(' Average batches loss: {} '.format(MeanDloss))\n",
        "       "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 494
        },
        "id": "hCv1y10rsafJ",
        "outputId": "e0375c94-692c-4a80-ecb8-0325a3cd1156"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x720 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "averageloss\n",
        "t=np.arange(0,n_epochs,1)\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(20,10))\n",
        "plt.title('Average Loss Error for {} Epochs. Learning Rate: {}'.format(n_epochs,learning_rate),fontsize=22)\n",
        "plt.plot(t,averageloss,color='r',label='Mean squar Error loss')\n",
        "#plt.plot(t,Gaverageloss,color='r',label='Generator Overal Error Gloss')\n",
        "#plt.plot(t,ADVloss,color='g',label='Gnerator Adversarial Error G_Adv')\n",
        "#plt.plot(t,MSEloss,color='y',label='Generator MS Error G_MSE')\n",
        "plt.xticks(np.arange(0,n_epochs,0.5))\n",
        "plt.yticks(np.arange(0,0.5,0.05))\n",
        "plt.xlabel('EPOCHS',fontsize=18)\n",
        "plt.ylabel('Error',fontsize=18)\n",
        "plt.gca().legend(prop={'size': 18})\n",
        "plt.grid(True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RYjYPWWZwXoc"
      },
      "outputs": [],
      "source": [
        "from testdatareader import TDataReader\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "batch_size=1\n",
        "test_data=TDataReader('ccv_data_fix/test')\n",
        "num_batches= test_data.num_batches_of_size(batch_size)\n",
        "A=np.arange(1601,1700,1)  \n",
        "with tf.Session() as sess:\n",
        "    sess.run(tf.global_variables_initializer())\n",
        "    for vb in range(num_batches):\n",
        "            images,images_names = test_data.get_batch(batchsize)\n",
        "            predictions = sess.run([normalized_output], feed_dict={x:images})\n",
        "            p = predictions[0]\n",
        "            p_arr = (p * 255.0).astype(np.uint8)\n",
        "            p_arr=p_arr.reshape(224,224)\n",
        "            p_image = Image.fromarray(p_arr)\n",
        "            \n",
        "            #print(p_image.shape)\n",
        "            p_image.save('predictions/'+ str(vb) + '_prediction' + '.' + 'jpeg')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "image_blur_detection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyM4m/ZTEVM8URZMsy8XUB49",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}